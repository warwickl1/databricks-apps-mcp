# Run unit tests and integration tests in Staging (test)
# Split into two jobs:
#   1 - Build the environment using `uv` and run pytest
#   2 - Validate the Databricks Asset Bundle in the 'test' environment
name: Training Unit and Integration Tests
permissions:
  contents: read
on:
  workflow_dispatch:
  pull_request:
    paths:
      - './**'
      - '.github/workflows/project-run-tests.yml'

concurrency: project-training-integration-test-staging

jobs:
  unit_tests:
    runs-on: ubuntu-latest
    environment: staging

    steps:
      # Setup
      - name: Checkout code
        uses: actions/checkout@v4
      - name: Set up Python
        uses: actions/setup-python@v5
      - name: Install uv
        uses: astral-sh/setup-uv@d4b2f3b6ecc6e67c4457f6d3e41ec42d3d0fcb86  # v5.4.2

      # Install dependencies
      - name: Install packages
        run: uv sync --all-extras --dev

      # Run tests
      - name: Run Unit Tests
        run: uv run -- pytest  || [[ $? -eq 5 ]]

  integration_tests:
    needs: unit_tests
    runs-on: ubuntu-latest
    environment: staging

    # Get secrets for Databricks
    env:
      DATABRICKS_TOKEN: ${{ secrets.STAGING_WORKSPACE_TOKEN }}
      
    steps:
      # Setup
      - name: Checkout code
        if: env.DATABRICKS_TOKEN != ''
        uses: actions/checkout@v4
      - name: Set up Databricks CLI
        if: env.DATABRICKS_TOKEN != ''
        uses: databricks/setup-cli@bf82b7a11475ed8d99eaf2920980fd091ca2cb12 # v0.221.1
      - name: Install uv
        if: env.DATABRICKS_TOKEN != ''
        uses: astral-sh/setup-uv@d4b2f3b6ecc6e67c4457f6d3e41ec42d3d0fcb86  # v5.4.2

      # Validate and deploy
      - name: Validate Bundle
        id: validate
        if: env.DATABRICKS_TOKEN != ''
        run: databricks bundle validate -t test --var="cluster_policy_id=${{ vars.STAGING_CLUSTER_POLICY_ID }}"
